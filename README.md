# Emotion-Music-Recommendation
Recommending music based on your facial expressions using FER 2013 dataset and Sporify api

## Project Description
The emotion recognition model, trained on the FER 2013 dataset, detects seven primary emotions. Utilizing a live video feed from a webcam, it processes each frame through the model to predict the dominant emotion. Based on this prediction, the application dynamically retrieves a curated playlist of songs from Spotify using the Spotipy wrapper. These recommended songs are then displayed on the screen, providing users with a personalized musical experience tailored to their current emotional state.

## Features
- Real-time expression detection: Utilizes live video feed from a webcam to detect facial expressions in real-time.
- Dynamic song recommendations: Based on the detected emotions, fetches curated playlists from Spotify's API, providing users with personalized song recommendations.
- Neumorphism UI design: Adopts the Neumorphism style for the website's user interface, blending soft shadows and highlights to create a modern, tactile appearance.
- User profiles: Allows users to create profiles to access personalized recommendations based on historical listening habits and emotional preferences.
  
## Running the app
Flask: 
- Run <code>pip install -r requirements.txt</code> to install all dependencies.
- In Spotipy.py enter your credentials generated by your Spotify Developer account in 'auth_manager'. Note: - This is only required if you want to update recommendation playlists. Also uncomment import statement in 'camera.py'.
- Run <code>python app.py</code> and give camera permission if asked.

## Model Architecture
- The model architecture is a sequential model consisting of Conv2d, Maxpool2d, Dropout and Dense layers:
1. Conv2D layers throughout the model have different filter size from 32 to 128, all with activation 'relu'
2. Pooling layers have pool size (2,2)
3. Dropout is set to 0.25 as anything above results in poor performance
4. Final Dense layer has 'softmax' activation for classifying 7 emotions

## Image Processing and Training
- The images were normalised, resized to (48,48) and converted to grayscale in batches of 64 with help of 'ImageDataGenerator' in Keras API.
- Training took around 13 hours locally for 75 epochs with an accuracy of ~66 %

## Current condition
The entire project works perfectly fine. Live detection gives good frame rates due to multithreading.

## Project Components
- Spotipy is a module for establishing connection to and getting tracks from Spotify using Spotipy wrapper.
- haarcascade is for face detection.
- camera.py is the module for video streaming, frame capturing, prediction and recommendation which are passed to main.py.
- main.py is the main flask application file.
- index.html in 'templates' directory is the web page for the application. Basic HTML and CSS.

## Screenshots
![Angry](https://github.com/AdityaSaxena1311/Emotion-Based-Music-Recommendation-System/assets/80876781/0ebefaf0-c4ec-42e7-8842-27f6bc781b0d)

![Fearful](https://github.com/AdityaSaxena1311/Emotion-Based-Music-Recommendation-System/assets/80876781/43eca7ef-4a28-4f1a-ba84-2aebaa84e7b1)

![Happy](https://github.com/AdityaSaxena1311/Emotion-Based-Music-Recommendation-System/assets/80876781/ec1dcb43-16f7-4437-b415-f66ff85f63ea)

![Sad](https://github.com/AdityaSaxena1311/Emotion-Based-Music-Recommendation-System/assets/80876781/570aee0d-0dfe-48ec-a412-3d48aaa4fc27)

![Surprised](https://github.com/AdityaSaxena1311/Emotion-Based-Music-Recommendation-System/assets/80876781/ad13de79-5f2c-4bf0-984c-b221e3491232)

